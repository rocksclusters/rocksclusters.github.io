<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">

<!--Converted with LaTeX2HTML 2002-2-1 (1.70)
original version by:  Nikos Drakos, CBLU, University of Leeds
* revised and updated by:  Marcus Hennecke, Ross Moore, Herb Swan
* with significant contributions from:
  Jens Lippmann, Marek Rouchal, Martin Wilck and others -->
<HTML>
<HEAD>
<TITLE>3.4 User Priorities and Negotiation</TITLE>
<META NAME="description" CONTENT="3.4 User Priorities and Negotiation">
<META NAME="keywords" CONTENT="ref">
<META NAME="resource-type" CONTENT="document">
<META NAME="distribution" CONTENT="global">

<META NAME="Generator" CONTENT="LaTeX2HTML v2002-2-1">
<META HTTP-EQUIV="Content-Style-Type" CONTENT="text/css">

<LINK REL="STYLESHEET" HREF="ref.css">

<LINK REL="next" HREF="3_5Policy_Configuration.html">
<LINK REL="previous" HREF="3_3Configuration.html">
<LINK REL="up" HREF="3_Administrators_Manual.html">
<LINK REL="next" HREF="3_5Policy_Configuration.html">
</HEAD>

<BODY  BGCOLOR=#FFFFFF >
<!--Navigation Panel-->
<A NAME="tex2html1119"
  HREF="3_5Policy_Configuration.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html1113"
  HREF="3_Administrators_Manual.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html1107"
  HREF="3_3Configuration.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html1115"
  HREF="Contents.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A> 
<A NAME="tex2html1117"
  HREF="Index.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index" SRC="index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html1120"
  HREF="3_5Policy_Configuration.html">3.5 Policy Configuration for</A>
<B> Up:</B> <A NAME="tex2html1114"
  HREF="3_Administrators_Manual.html">3. Administrators' Manual</A>
<B> Previous:</B> <A NAME="tex2html1108"
  HREF="3_3Configuration.html">3.3 Configuration</A>
 &nbsp; <B>  <A NAME="tex2html1116"
  HREF="Contents.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html1118"
  HREF="Index.html">Index</A></B> 
<BR>
<BR>
<!--End of Navigation Panel-->
<!--Table of Child-Links-->
<A NAME="CHILD_LINKS"><STRONG>Subsections</STRONG></A>

<UL>
<LI><A NAME="tex2html1121"
  HREF="3_4User_Priorities.html#SECTION00441000000000000000">3.4.1 Real User Priority (RUP)</A>
<LI><A NAME="tex2html1122"
  HREF="3_4User_Priorities.html#SECTION00442000000000000000">3.4.2 Effective User Priority (EUP)</A>
<LI><A NAME="tex2html1123"
  HREF="3_4User_Priorities.html#SECTION00443000000000000000">3.4.3 Priorities in Negotiation and Preemption</A>
<LI><A NAME="tex2html1124"
  HREF="3_4User_Priorities.html#SECTION00444000000000000000">3.4.4 Priority Calculation</A>
<LI><A NAME="tex2html1125"
  HREF="3_4User_Priorities.html#SECTION00445000000000000000">3.4.5 Negotiation</A>
<LI><A NAME="tex2html1126"
  HREF="3_4User_Priorities.html#SECTION00446000000000000000">3.4.6 The Layperson's Description of the Pie Spin and Pie Slice</A>
<LI><A NAME="tex2html1127"
  HREF="3_4User_Priorities.html#SECTION00447000000000000000">3.4.7 Group Accounting</A>
<LI><A NAME="tex2html1128"
  HREF="3_4User_Priorities.html#SECTION00448000000000000000">3.4.8 Group Quotas</A>
</UL>
<!--End of Table of Child-Links-->
<HR>

<H1><A NAME="SECTION00440000000000000000"></A><A NAME="sec:UserPrio"></A>
<BR>
3.4 User Priorities and Negotiation
</H1>

<P>
<A NAME="23836"></A>
<A NAME="23837"></A>
Condor uses priorities to determine machine allocation for jobs.
This section details the priorities and the allocation of
machines (negotiation).

<P>
For accounting purposes, each user is identified by username@uid_domain.
Each user is assigned a priority value even if submitting jobs from
different machines in the same domain, or even if submitting from multiple
machines in the different domains.

<P>
The numerical priority value assigned to a user is inversely related to the 
<I>goodness</I> of the priority.
A user with a numerical priority of 5 gets 
more resources than a user with a numerical priority of 50.
There are two 
priority values assigned to Condor users:

<UL>
<LI>Real User Priority (RUP), which measures resource usage of the 
		user.
</LI>
<LI>Effective User Priority (EUP), which determines the number of
		resources the user can get.
</LI>
</UL>
This section describes these two priorities and how they affect resource
allocations in Condor.
Documentation on configuring and controlling 
priorities may be found in section&nbsp;<A HREF="3_3Configuration.html#sec:Negotiator-Config-File-Entries">3.3.17</A>.

<P>

<H2><A NAME="SECTION00441000000000000000"></A><A NAME="sec:RUP"></A>
<A NAME="23843"></A>
<A NAME="23844"></A>
<BR>
3.4.1 Real User Priority (RUP)
</H2>
A user's RUP measures the resource usage of the user 
through time.
Every user begins with a RUP of one half (0.5), and
at steady state, the RUP of a user equilibrates to the number of resources 
used by that user.  Therefore, if a specific user continuously uses exactly 
ten resources for a long period of time, the RUP of that user stabilizes at 
ten.

<P>
However, if the user decreases the number of resources used, the RUP
gets better.  The rate at which the priority value decays 
can be set by the macro <TT>PRIORITY_HALFLIFE</TT> <A NAME="24008"></A> <A NAME="24009"></A>, a time period 
defined in seconds.   Intuitively, if the <TT>PRIORITY_HALFLIFE</TT> <A NAME="24013"></A> <A NAME="24014"></A> in a pool 
is set to 86400 (one day), and if a user whose RUP was 10 removes all his 
jobs, the user's RUP would be 5 one day later, 2.5 two days later,
and so on.

<P>

<H2><A NAME="SECTION00442000000000000000"></A><A NAME="sec:EUP"></A>
<A NAME="23848"></A>
<A NAME="23849"></A>
<BR>
3.4.2 Effective User Priority (EUP)
</H2>
The effective user priority (EUP) of a user is used to determine
how many resources that user may receive.
The EUP is linearly related to the RUP
by a <I>priority factor</I> which may be defined on a per-user basis.
Unless otherwise configured, the priority factor for all users is 1.0,
and so the EUP is the same as the the RUP.
However, if desired, the priority factors of
specific users (such as remote submitters) can be increased so that 
others are served preferentially.

<P>
The number of resources that a user may receive is inversely related
to the ratio between the EUPs of submitting users.
Therefore user <I>A</I> with EUP=5 will receive
twice as many resources as user <I>B</I> with EUP=10 and four times as many 
resources as user <I>C</I> with EUP=20.
However, if <I>A</I> does not use the full number
of allocated resources,
the available resources are repartitioned and distributed among
remaining users according to the inverse ratio rule.

<P>
Condor supplies mechanisms to directly support two policies in which EUP may
be useful:
<DL>
<DT><STRONG>Nice users</STRONG></DT>
<DD>A job may be submitted with the parameter 
	<TT>nice_user</TT> set to TRUE in the submit command file.
	A nice user job gets its RUP boosted by the 
	<TT>NICE_USER_PRIO_FACTOR</TT> <A NAME="24019"></A> <A NAME="24020"></A> priority factor specified in the 
	configuration file, leading to a (usually very large) EUP.
	This corresponds to a low priority for resources.
	These jobs are therefore equivalent to Unix background jobs,
	which use resources not used by other Condor users.

<P>
</DD>
<DT><STRONG>Remote Users</STRONG></DT>
<DD>The flocking feature of Condor (see
	section&nbsp;<A HREF="5_2Connecting_Condor.html#sec:Flocking">5.2</A>) allows the <I>condor_schedd</I> to
	submit to more than one pool.
	In addition, the submit-only feature allows a user to run a
	<I>condor_schedd</I> that is submitting jobs into another pool.
	In such situations, submitters from other domains
	can submit to the local pool.
	It is often desirable to have Condor treat local users
	preferentially over these remote users.
	If configured, Condor will boost the RUPs of remote users by
	<TT>REMOTE_PRIO_FACTOR</TT> <A NAME="24028"></A> <A NAME="24029"></A>
	specified in the configuration file,
	thereby lowering their priority for resources.
</DD>
</DL>

<P>
The priority boost factors for individual users can be set with the 
<B>setfactor</B> option of <I>condor_userprio</I>.
Details may be found in the <I>condor_userprio</I> manual page 
on page&nbsp;<A HREF="condor_userprio.html#man-condor-userprio"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]" SRC="crossref.png"></A>.

<P>

<H2><A NAME="SECTION00443000000000000000"></A>
<A NAME="23864"></A>
<A NAME="23865"></A>
<A NAME="23866"></A>
<BR>
3.4.3 Priorities in Negotiation and Preemption
</H2>
Priorities are used to ensure that users get their fair share of resources.  
The priority values are used at allocation time, meaning during
negotiation and matchmaking.
Therefore, there are ClassAd attributes that take on defined values
only during negotiation, making them ephemeral.
In addition to allocation, Condor may preempt a machine claim 
and reallocate it when conditions change.

<P>
Too many preemptions lead to thrashing,
a condition in which negotiation for a machine identifies a
new job with a better priority most every cycle.
Each job is, in turn, preempted, and no job finishes.
To avoid this situation, the <TT>PREEMPTION_REQUIREMENTS</TT> <A NAME="24039"></A> <A NAME="24040"></A> 
configuration variable is defined for and used only by 
the <I>condor_negotiator</I> daemon
to specify the conditions that must be met for a preemption to
occur.  It is usually defined to deny preemption if a current running
job has been running for a relatively short period of time.  This
effectively limits the number of preemptions per resource per time
interval.
Note that <TT>PREEMPTION_REQUIREMENTS</TT> only applies to preemptions
due to user priority.  It does not have any effect if the machine's 
<TT>RANK</TT>
expression prefers a different job, or if the machine's policy
causes the job to vacate due to other activity on the machine.
See section <A HREF="3_5Policy_Configuration.html#sec:Disabling_Preemption">3.5.9</A> for a general discussion of
limiting preemption.

<P>
The following ephemeral attributes may be used within policy definitions.
Care should be taken when using these attributes, 
due to their ephemeral nature;
they are not always defined, so the usage of an expression to 
check if defined such as
<PRE>
  (RemoteUserPrio =?= UNDEFINED)
</PRE>
is likely necessary.

<P>
Within these attributes, those with names that contain the
string <TT>Submitter</TT> refer to characteristics about the candidate job's user;
those with names that contain the string <TT>Remote</TT>
refer to characteristics about the user currently using the resource.
Further,  those with names that end with the
string <TT>ResourcesInUse</TT> have values that may change within
the time period associated with a single negotiation cycle.
Therefore, the configuration variables <TT>PREEMPTION_REQUIREMENTS_STABLE</TT> <A NAME="24051"></A> <A NAME="24052"></A>
and and <TT>PREEMPTION_RANK_STABLE</TT> <A NAME="24056"></A> <A NAME="24057"></A> exist to inform the 
<I>condor_negotiator</I> daemon that values may change.
See section&nbsp;<A HREF="3_3Configuration.html#param:PreemptionRequirementsStable">3.3.17</A> on
page&nbsp;<A HREF="3_3Configuration.html#param:PreemptionRequirementsStable"><IMG  ALIGN="BOTTOM" BORDER="1" ALT="[*]" SRC="crossref.png"></A> for
definitions of these configuration variables.

<P>
<DL>
<DT><STRONG><A NAME="23883"></A><TT>SubmitterUserPrio</TT>:</STRONG></DT>
<DD>A floating point value representing the user priority of the 
  candidate job.
</DD>
<DT><STRONG><A NAME="23885"></A><TT>SubmitterUserResourcesInUse</TT>:</STRONG></DT>
<DD>The integer number of slots currently utilized by the user
  submitting the candidate job.
</DD>
<DT><STRONG><A NAME="23887"></A><TT>RemoteUserPrio</TT>:</STRONG></DT>
<DD>A floating point value representing the user priority of the 
  job currently running on the machine.
  This version of the attribute, with no slot represented in the attribute name,
  refers to the current slot being evaluated.
</DD>
<DT><STRONG><A NAME="23889"></A><TT>Slot&lt;N&gt;_RemoteUserPrio</TT>:</STRONG></DT>
<DD>A floating point value representing the user priority of the 
  job currently running on the particular slot represented
  by <code>&lt;N&gt;</code> on the machine.
</DD>
<DT><STRONG><A NAME="23891"></A><TT>RemoteUserResourcesInUse</TT>:</STRONG></DT>
<DD>The integer number of slots currently utilized by the user
  of the job currently running on the machine.
</DD>
<DT><STRONG><A NAME="23893"></A><TT>SubmitterGroupResourcesInUse</TT>:</STRONG></DT>
<DD>If the owner of the candidate job is a member of a valid accounting group,
  with a defined group quota,
  then this attribute is the integer number of slots currently 
  utilized by the group.
</DD>
<DT><STRONG><A NAME="23895"></A><TT>SubmitterGroupQuota</TT>:</STRONG></DT>
<DD>If the owner of the candidate job is a member of a valid accounting group,
  with a defined group quota,
  then this attribute is the integer number of slots defined as the
  group's quota.
</DD>
<DT><STRONG><A NAME="23897"></A><TT>RemoteGroupResourcesInUse</TT>:</STRONG></DT>
<DD>If the owner of the currently running job is a member of a valid 
  accounting group, with a defined group quota,
  then this attribute is the integer number of slots currently 
  utilized by the group.
</DD>
<DT><STRONG><A NAME="23899"></A><TT>RemoteGroupQuota</TT>:</STRONG></DT>
<DD>If the owner of the currently running job is a member of a valid 
  accounting group, with a defined group quota,
  then this attribute is the integer number of slots defined as the
  group's quota.

<P>
</DD>
</DL>

<P>

<H2><A NAME="SECTION00444000000000000000">
3.4.4 Priority Calculation</A>
</H2>
This section may be skipped if the reader so feels, but for the curious,
here is Condor's priority calculation algorithm.

<P>
The RUP of a user <I>u</I> at time <I>t</I>, <IMG
 WIDTH="54" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img19.png"
 ALT="$\pi_r(u,t)$">, is calculated 
every time interval <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img20.png"
 ALT="$\delta t$"> using the formula 
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
\pi_r(u,t) = \beta\times\pi(u,t-\delta t) + (1-\beta)\times\rho(u,t)
\end{displaymath}
 -->

<IMG
 WIDTH="308" HEIGHT="28" BORDER="0"
 SRC="img21.png"
 ALT="\begin{displaymath}\pi_r(u,t) = \beta\times\pi(u,t-\delta t) + (1-\beta)\times\rho(u,t)\end{displaymath}">
</DIV>
<BR CLEAR="ALL">
<P></P>
where <IMG
 WIDTH="47" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img22.png"
 ALT="$\rho(u,t)$"> is the number of resources used by user <I>u</I> at time <I>t</I>,
and <!-- MATH
 $\beta=0.5^{{\delta t}/h}$
 -->
<IMG
 WIDTH="81" HEIGHT="36" ALIGN="MIDDLE" BORDER="0"
 SRC="img23.png"
 ALT="$\beta=0.5^{{\delta t}/h}$">. <I>h</I> is the half life period set by 
<TT>PRIORITY_HALFLIFE</TT> <A NAME="24072"></A> <A NAME="24073"></A>.

<P>
The EUP of user <I>u</I> at time <I>t</I>, <IMG
 WIDTH="54" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img24.png"
 ALT="$\pi_e(u,t)$">
is calculated by
<BR><P></P>
<DIV ALIGN="CENTER">
<!-- MATH
 \begin{displaymath}
\pi_e(u,t) = \pi_r(u,t)\times f(u,t)
\end{displaymath}
 -->

<IMG
 WIDTH="184" HEIGHT="28" BORDER="0"
 SRC="img25.png"
 ALT="\begin{displaymath}\pi_e(u,t) = \pi_r(u,t)\times f(u,t)\end{displaymath}">
</DIV>
<BR CLEAR="ALL">
<P></P>
where <I>f</I>(<I>u</I>,<I>t</I>) is the priority boost factor for user <I>u</I> at time <I>t</I>.

<P>
As mentioned previously, the RUP calculation is designed so that at steady
state, each user's RUP stabilizes at the number of resources used by that user. 
The definition of <IMG
 WIDTH="14" HEIGHT="29" ALIGN="MIDDLE" BORDER="0"
 SRC="img26.png"
 ALT="$\beta$"> ensures that the calculation of <IMG
 WIDTH="54" HEIGHT="31" ALIGN="MIDDLE" BORDER="0"
 SRC="img19.png"
 ALT="$\pi_r(u,t)$"> can be 
calculated over non-uniform time intervals <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img20.png"
 ALT="$\delta t$"> without affecting the 
calculation.  The time interval <IMG
 WIDTH="17" HEIGHT="14" ALIGN="BOTTOM" BORDER="0"
 SRC="img20.png"
 ALT="$\delta t$"> varies due to events internal to 
the system, but Condor guarantees that unless the central manager machine is 
down, no matches will be unaccounted for due to this variance.

<P>

<H2><A NAME="SECTION00445000000000000000"></A><A NAME="sec:negotiation"></A>
<A NAME="23906"></A>
<A NAME="23907"></A>
<BR>
3.4.5 Negotiation
</H2>

<P>
Negotiation is the method Condor undergoes periodically to
match queued jobs with resources capable of running jobs.
The <I>condor_negotiator</I> daemon is responsible for
negotiation.

<P>
During a negotiation cycle, the <I>condor_negotiator</I> daemon
accomplishes the following ordered list of items.

<OL>
<LI>Build a list of all possible resources,
  regardless of the state of those resources.
</LI>
<LI>Obtain a list of all job submitters (for the entire pool).
</LI>
<LI>Sort the list of all job submitters based on EUP
  (see section&nbsp;<A HREF="#sec:EUP">3.4.2</A> for an explanation of EUP).
  The submitter with the best priority is first within the sorted list.
</LI>
<LI>Iterate until there are either no more resources to match,
  or no more jobs to match.
    <DL>
<DT></DT>
<DD>For each submitter (in EUP order):
        <DL>
<DT></DT>
<DD>For each submitter, get each job.
	  Since jobs may be submitted from more than one machine
	  (hence to more than one <I>condor_schedd</I> daemon),
	  here is a further definition of the ordering of these jobs.
	  With jobs from a single <I>condor_schedd</I> daemon, 
	  jobs are typically returned in job priority order.
	  When more than one <I>condor_schedd</I> daemon is involved,
	  they are contacted in an undefined order. 
	  All jobs from a single <I>condor_schedd</I> daemon are considered
	  before moving on to the next.
	  For each job:
              
<UL>
<LI>For each machine in the pool that can execute jobs:
                  
<OL>
<LI>If <TT>machine.requirements</TT> evaluates to
		  <TT>False</TT> or
		  <TT>job.requirements</TT> evaluates to <TT>False</TT>,
		  skip this machine
</LI>
<LI>If the machine is in the Claimed state, but
		  not running a job, skip this machine.
</LI>
<LI>If this machine is not running a job, add it to
		  the potential match list by reason of
		  No Preemption.
</LI>
<LI>If the machine is running a job
                    
<UL>
<LI>If the <TT>machine.RANK</TT> on this job is
		    better than the running job, add this machine to the
		    potential match list by reason of Rank.
</LI>
<LI>If the EUP of this job is better than the EUP
		    of the currently running job, and
		    <TT>PREEMPTION_REQUIREMENTS</TT> is <TT>True</TT>,
		    and the <TT>machine.RANK</TT> on this job is not worse
		    than the currently running job, add this machine to the
		    potential match list by reason of Priority.
                    
</LI>
</UL>
</LI>
</OL>
</LI>
<LI>Of machines in the potential match list, sort by
		<TT>NEGOTIATOR_PRE_JOB_RANK</TT>, <TT>job.RANK</TT>,
		<TT>NEGOTIATOR_POST_JOB_RANK</TT>, Reason for claim
		(No Preemption, then Rank, then Priority),
		<TT>PREEMPTION_RANK</TT>
</LI>
<LI>The job is assigned to the top machine on the
		potential match list.  The machine is removed
		from the list of resources to match
		(on this negotiation cycle).
              
</LI>
</UL>
</DD>
</DL>
</DD>
</DL>
</LI>
</OL>

<P>
The <I>condor_negotiator</I> asks the <I>condor_schedd</I> for the 
"next job" from a given submitter/user.
Typically, the <I>condor_schedd</I> returns jobs in the order of
job priority.
If priorities are the same,
job submission time is used; older jobs go first.
If a cluster has multiple procs in it and one of the jobs cannot be matched,
the <I>condor_schedd</I> will not return any more jobs in that cluster
on that negotiation pass.
This is an optimization based on the theory that the cluster jobs are similar.
The configuration variable <TT>NEGOTIATE_ALL_JOBS_IN_CLUSTER</TT> <A NAME="24109"></A> <A NAME="24110"></A>
disables the cluster-skipping optimization.
Use of the configuration variable <TT>SIGNIFICANT_ATTRIBUTES</TT> <A NAME="24114"></A> <A NAME="24115"></A>
will change the
definition of what the <I>condor_schedd</I> considers a cluster from the
default definition of all jobs that share the same <TT>ClusterId</TT>.

<P>

<H2><A NAME="SECTION00446000000000000000"></A><A NAME="sec:PieSlice"></A>
<A NAME="23948"></A>
<A NAME="23949"></A>
<A NAME="23950"></A>
<A NAME="23951"></A>
<BR>
3.4.6 The Layperson's Description of the Pie Spin and Pie Slice
</H2>

<P>
Condor schedules in a variety of ways.
First, it takes all users who have submitted jobs and calculates their priority.
Then, it totals the number of resources available at the moment,
and using the ratios of the user priorities,
it calculates the number of machines each user could get.
This is their <I>pie slice</I>.

<P>
The Condor matchmaker goes in user priority order, 
contacts each user, and asks for job information. 
The <I>condor_schedd</I> daemon (on behalf of a user)
tells the matchmaker about a job,
and the matchmaker looks at available resources
to create a list of resources that match the requirements expression.
With the list of resources that match,
it sorts them according to the rank expressions within ClassAds.
If a machine prefers a job, the job is assigned to that machine,
potentially preempting a job that might already be running on that machine.
Otherwise, give the machine to the job that the job ranks highest.
If the machine ranked highest is already running a job,
we may preempt running job
for the new job. 
A default policy for preemption states that the user must
have a 20%  better priority in order for preemption to succeed.
If the job has no preferences as to what sort of machine it gets,
matchmaking gives it the first idle resource to meet its requirements.

<P>
This matchmaking cycle continues until the user has received all of the
machines in their pie slice.
The matchmaker then contacts the next highest
priority user and offers that user their pie slice worth of machines.
After contacting all users,
the cycle is repeated with any still available resources
and recomputed pie slices.
The matchmaker continues <I>spinning the pie</I> 
until it runs out of machines or all the <I>condor_schedd</I> daemons
say they have no more jobs. 

<P>

<H2><A NAME="SECTION00447000000000000000"></A><A NAME="sec:group-accounting"></A>
<A NAME="23957"></A>
<A NAME="23958"></A>
<A NAME="23959"></A>
<BR>
3.4.7 Group Accounting
</H2>

<P>
By default, Condor does all accounting on a per-user basis, and this
accounting is primarily used to compute priorities for Condor's
fair-share scheduling algorithms. 
However, accounting can also be done on a per-group basis.
Multiple users can all submit jobs into the same accounting group,
and all of the jobs will be treated with the same priority.

<P>
<A NAME="23960"></A>
To use an accounting group,
each job inserts an attribute into the job ClassAd which
defines the accounting group name for the job.
A common name is decided upon and used for the group.
The following line is an example that defines the attribute
within the job's submit description file:
<PRE>
+AccountingGroup = "group_physics"
</PRE>

<P>
The <TT>AccountingGroup</TT> attribute is a string,
and it therefore must be enclosed in double quote marks.
The string may have a maximum length of 40 characters.
The name should <I>not</I> be qualified with a domain.
Certain parts of the Condor system 
do append the value <TT>$(UID_DOMAIN)</TT>
(as specified in the configuration file on the submit machine)
to this string for internal use.
For example, if the value of <TT>UID_DOMAIN</TT> is
<TT>example.com</TT>, and the accounting group name
is as specified,
<I>condor_userprio</I> will show statistics
for this accounting group using the appended domain, for example
<PRE>
                                    Effective
User Name                           Priority
------------------------------      ---------
group_physics@example.com                0.50
user@example.com                        23.11
heavyuser@example.com                  111.13
...
</PRE>
<P>
Additionally, the <I>condor_userprio</I> command allows administrators to
remove an entity from the accounting system in Condor.
The <B>-delete</B> option to <I>condor_userprio</I>
accomplishes this
if all the jobs from a given accounting group are completed,
and the administrator wishes to remove that group from the system.
The <B>-delete</B> option
identifies the accounting group with the fully-qualified name
of the accounting group.
For example
<PRE>
condor_userprio -delete group_physics@example.com
</PRE>
<P>
Condor removes entities itself as they are no longer
relevant.
Intervention by an administrator to delete entities can
be beneficial when the use of thousands
of short term accounting groups leads to scalability
issues.

<P>
Note that the name of an accounting group may include a period (.).
Inclusion of a period character in the accounting group name
only has relevance if the portion of the name before the
period matches a group name,
as described in the next section on group quotas.

<P>

<H2><A NAME="SECTION00448000000000000000"></A><A NAME="sec:group-quotas"></A>
<BR>
3.4.8 Group Quotas
</H2>

<P>
<A NAME="23978"></A>
<A NAME="23979"></A>
<A NAME="23980"></A>
The use of group quotas modifies the negotiation for 
available resources (machines) within a Condor pool.
This solves the difficulties inherent when
priorities assigned based on each single user are insufficient.
This may be the case when
different groups (of varying size) own computers,
and the groups choose to combine their computers to
form a Condor pool.
Consider an imaginary Condor pool example with thirty computers;
twenty computers are owned by the physics group and ten
computers are owned by the chemistry group.
One notion of fair allocation could be implemented 
by configuring the twenty machines owned by the physics group
to prefer (using the <TT>RANK</TT> configuration macro)
jobs submitted by the users identified as associated
with the physics group.
Likewise, the ten machines owned by the chemistry group are
configured to prefer jobs from users associated with the
the chemistry group.
This routes jobs to execute on specific machines,
perhaps causing more preemption than necessary.
The (fair allocation) policy desired is likely somewhat different,
if these thirty machines have been pooled.
The desired policy does not tie users to specific sets of machines,
but to numbers of machines (a quota).
Given thirty similar machines,
the desired policy allows users within the physics group to have
preference on up to twenty of the machines within the pool,
and the machines can be any of the machines that are available.

<P>
A quota for a set of users requires an identification of
the set; members are called group users.
Jobs under the group quota
specify the group user with the 
<TT>AccountingGroup</TT> job ClassAd attribute.
This is the same attribute as is used with group accounting.

<P>
The submit file syntax for specifying a group user includes 
both a group name and a user name.
The syntax is
<PRE>
  +AccountingGroup = "&lt;group&gt;.&lt;user&gt;"
</PRE>
The <code>group</code> is a name chosen for the group.
Group names are case-insensitive for negotiation.
Group names are not required to begin with the
string <TT>"group_"</TT>,
as in the examples
<TT>"group_physics.newton"</TT> and <TT>"group_chemistry.curie"</TT>,
but it is a useful convention,
because group names must not conflict with user names.
The period character between the group and the user name is
a required part of the syntax.  <U>NOTE</U>: An accounting
group value lacking the period will cause the job to not 
be considered part of the
group when negotiating, even if the group name has a quota.
Furthermore, there will be no warnings that the group quota is not
in effect for the job, as this syntax defines group accounting.

<P>
Configuration controls the order of negotiation for
groups and individual users,
as well as sets quotas
(preferentially allocated numbers of machines)
for the groups.
A declared number of slots specifies the quota for each group
(see <TT>GROUP_QUOTA_&lt;groupname&gt;</TT>
in section&nbsp;<A HREF="3_3Configuration.html#param:GroupQuotaGroupname">3.3.17</A>).
The sum of the quotas for all groups should typically be less than or equal to
the number of slots in the entire pool, but there are situations where it
can make sense to have the sum be greater than the size of the pool.
An example of this is where large quotas can be used to give 
some groups a chance to
claim all slots before other groups have a chance to claim any.
If the sum is less than the number of
slots in the entire pool,
the slots are 
allocated to the <code>none</code> group,
comprised of the general
users not submitting jobs in a group.

<P>
Where group users are specified for jobs,
accounting is done per group user.
It is no longer done by group, or by individual user.

<P>
Negotiation is changed when group quotas are used.
Condor negotiates first for defined groups,
and then for independent job submitters.
Given jobs belonging to different groups,
Condor negotiates first for the group 
currently utilizing the smallest percentage of machines
in its quota.
After this,
Condor negotiates for the group 
currently utilizing the second smallest percentage of machines
in its quota.
The last group will be the one with the highest percentage
of machines in its quota.
As an example, again use the imaginary pool and groups 
given above.
If various users within <code>group_physics</code> have
jobs running on 15 computers, 
then the physics group has 75% of the 
machines within its quota.
If various users within <code>group_chemistry</code> have
jobs running on 5 computers, 
then the chemistry group has 50% of the 
machines within its quota.
Negotiation will take place for the chemistry group first.
For independent job submissions (those not part of any group),
the classic Condor user fair share algorithm still applies.

<P>
Note that there is no verification that a user is a member of
the group that he claims.
We rely on societal pressure for enforcement. 

<P>
Configuration variables affect group quotas.
See section&nbsp;<A HREF="3_3Configuration.html#sec:Negotiator-Config-File-Entries">3.3.17</A> for detailed
descriptions of the variables mentioned.
Group names that may be given quotas to be used in
negotiation are listed in the <TT>GROUP_NAMES</TT> <A NAME="24149"></A> <A NAME="24150"></A> macro.
The names chosen must not conflict with Condor user names.
Quotas (by group) are defined in numbers of machine slots.
Each group may be assigned an initial value for its
user priority factor with the <TT>GROUP_PRIO_FACTOR_&lt;groupname&gt;</TT> <A NAME="24154"></A> <A NAME="24155"></A>
macro.
If a group is currently allocated its entire quota of machines,
and a group user has a submitted job that is not running,
the <TT>GROUP_AUTOREGROUP</TT> <A NAME="24159"></A> <A NAME="24160"></A> macro allows the job to be
considered a second time within the negotiation cycle
along with all other individual users' jobs.

<P>
<PRE>
  ####################
  #
  # Example 1
  # Configuration for group quotas
  #
  ####################

  GROUP_NAMES = group_physics, group_chemistry
  GROUP_QUOTA_group_physics = 20
  GROUP_QUOTA_group_chemistry = 10
  GROUP_PRIO_FACTOR_group_physics = 1.0
  GROUP_PRIO_FACTOR_group_chemistry = 3.0
  GROUP_AUTOREGROUP_group_physics = FALSE
  GROUP_AUTOREGROUP_group_chemistry = TRUE
</PRE>

<P>
This configuration specifies that the <code>group_physics</code> users will
get 20 machines and the <code>group_chemistry</code> users will get
ten machines.  <code>group_physics</code> users will never get more than
20 machines; however, <code>group_chemistry</code> users can potentially get
more than ten machines because <TT>GROUP_AUTOREGROUP_chemistry</TT>
is true.
This could happen, for example, if there are only 15 jobs
submitted by <code>group_physics</code> users.
Also, the default priority
factor for the physics groups is 1.0, and the default priority factor
for the chemistry group is 3.0.

<P>
<PRE>
  ####################
  #
  # Submit description file for group quota user
  #
  ####################
  ...
  +AccountingGroup = "group_physics.newton"
  ...
</PRE>

<P>
This submit file specifies that this job is to be negotiated as part of
the <code>group_physics</code> group and that the user is newton.
Remember that
both the group name and the user name are required for the group quota
to take effect.
<HR>
<!--Navigation Panel-->
<A NAME="tex2html1119"
  HREF="3_5Policy_Configuration.html">
<IMG WIDTH="37" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="next" SRC="next.png"></A> 
<A NAME="tex2html1113"
  HREF="3_Administrators_Manual.html">
<IMG WIDTH="26" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="up" SRC="up.png"></A> 
<A NAME="tex2html1107"
  HREF="3_3Configuration.html">
<IMG WIDTH="63" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="previous" SRC="prev.png"></A> 
<A NAME="tex2html1115"
  HREF="Contents.html">
<IMG WIDTH="65" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="contents" SRC="contents.png"></A> 
<A NAME="tex2html1117"
  HREF="Index.html">
<IMG WIDTH="43" HEIGHT="24" ALIGN="BOTTOM" BORDER="0" ALT="index" SRC="index.png"></A> 
<BR>
<B> Next:</B> <A NAME="tex2html1120"
  HREF="3_5Policy_Configuration.html">3.5 Policy Configuration for</A>
<B> Up:</B> <A NAME="tex2html1114"
  HREF="3_Administrators_Manual.html">3. Administrators' Manual</A>
<B> Previous:</B> <A NAME="tex2html1108"
  HREF="3_3Configuration.html">3.3 Configuration</A>
 &nbsp; <B>  <A NAME="tex2html1116"
  HREF="Contents.html">Contents</A></B> 
 &nbsp; <B>  <A NAME="tex2html1118"
  HREF="Index.html">Index</A></B> 
<!--End of Navigation Panel-->
<ADDRESS>
condor-admin@cs.wisc.edu
</ADDRESS>
</BODY>
</HTML>
